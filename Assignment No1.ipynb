{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a536fec5",
   "metadata": {},
   "source": [
    "# ASSIGNMENT 1\n",
    "\n",
    "WEB SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509bdf7",
   "metadata": {},
   "source": [
    "Q-1-Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7faaf578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c4906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page') # Send request to webserver to get the source code\n",
    "\n",
    "soup = BeautifulSoup(page.content) # To Assign the page content to the variable soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cc14c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 ---- Main Page\n",
      "h1 ---- Welcome to Wikipedia\n",
      "h2 ---- From today's featured article\n",
      "h2 ---- Did you know ...\n",
      "h2 ---- In the news\n",
      "h2 ---- On this day\n",
      "h2 ---- Today's featured picture\n",
      "h2 ---- Other areas of Wikipedia\n",
      "h2 ---- Wikipedia's sister projects\n",
      "h2 ---- Wikipedia languages\n",
      "h2 ---- Navigation menu\n",
      "h3 ---- Personal tools\n",
      "h3 ---- Namespaces\n",
      "h3 ---- Views\n",
      "h3 ---- Search\n",
      "h3 ---- Navigation\n",
      "h3 ---- Contribute\n",
      "h3 ---- Tools\n",
      "h3 ---- Print/export\n",
      "h3 ---- In other projects\n",
      "h3 ---- Languages\n"
     ]
    }
   ],
   "source": [
    "header_tags = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"] # assign all type of header tags to a variable as list\n",
    "for tags in soup.find_all(header_tags):            # pass that list in the method to find the function\n",
    "    print(tags.name + ' ---- ' + tags.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e81c857",
   "metadata": {},
   "source": [
    "Q-2- Write a python program to display IMDB's Top rated 100 Indian movies' data (i.e. name, rating, year of release) and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f74eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e537fb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Names</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      Rocketry: The Nambi Effect(2022)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      Anbe Sivam(2003)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      Jai Bhim(2021)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      Golmaal(1979)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      Nayakan(1987)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.      Ustad Hotel(2012)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.      The Legend of Bhagat Singh(2002)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.      Virumandi(2004)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.      Baahubali 2: The Conclusion(2017)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.      Angoor(1982)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Movie Names Ratings\n",
       "0     1.      Rocketry: The Nambi Effect(2022)     8.5\n",
       "1                     2.      Anbe Sivam(2003)     8.4\n",
       "2                       3.      Jai Bhim(2021)     8.4\n",
       "3                        4.      Golmaal(1979)     8.4\n",
       "4                        5.      Nayakan(1987)     8.4\n",
       "..                                         ...     ...\n",
       "95                  96.      Ustad Hotel(2012)     8.0\n",
       "96   97.      The Legend of Bhagat Singh(2002)     8.0\n",
       "97                    98.      Virumandi(2004)     8.0\n",
       "98  99.      Baahubali 2: The Conclusion(2017)     8.0\n",
       "99                      100.      Angoor(1982)     8.0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/') # Send request to webserver to get the source code\n",
    "\n",
    "ind_soup = BeautifulSoup(page.content) # To Assign the page content to the variable soup\n",
    "ind_movietitle = ind_soup.find_all('td', class_=\"titleColumn\")\n",
    "ind_movietitle\n",
    "\n",
    "ind_movies = []\n",
    "\n",
    "for ind_movie in ind_movietitle:\n",
    "    ind_movie = ind_movie.get_text().replace('\\n', \"\")\n",
    "    ind_movie = ind_movie.strip(\" \")\n",
    "    ind_movies.append(ind_movie)\n",
    "ind_movies[:100]\n",
    "    \n",
    "ind_scraped_ratings = ind_soup.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "ind_ratings = []\n",
    "for ind_rating in ind_scraped_ratings:\n",
    "    ind_rating = ind_rating.get_text().replace('\\n', '')\n",
    "    ind_ratings.append(ind_rating)\n",
    "ind_ratings\n",
    "\n",
    "import pandas as pd\n",
    "ind_data = pd.DataFrame()\n",
    "ind_data['Movie Names'] = ind_movies[:100]\n",
    "ind_data['Ratings'] = ind_ratings[:100]\n",
    "ind_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1947efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-3- Write a python program to display IMDB's Top rated 100  movies' data (i.e. name, rating, year of release) and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8be4118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Names</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      The Shawshank Redemption(1994)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      The Godfather(1972)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      The Dark Knight(2008)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      The Godfather Part II(1974)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      12 Angry Men(1957)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>246.      Dersu Uzala(1975)</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>247.      Aladdin(1992)</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248.      Gandhi(1982)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249.      The Help(2011)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250.      The Iron Giant(1999)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Movie Names Ratings\n",
       "0    1.      The Shawshank Redemption(1994)     8.5\n",
       "1               2.      The Godfather(1972)     8.4\n",
       "2             3.      The Dark Knight(2008)     8.4\n",
       "3       4.      The Godfather Part II(1974)     8.4\n",
       "4                5.      12 Angry Men(1957)     8.4\n",
       "..                                      ...     ...\n",
       "245             246.      Dersu Uzala(1975)     7.7\n",
       "246                 247.      Aladdin(1992)     7.7\n",
       "247                  248.      Gandhi(1982)     7.6\n",
       "248                249.      The Help(2011)     7.6\n",
       "249          250.      The Iron Giant(1999)     7.6\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/chart/top/?ref_=nv_mv_250') # Send request to webserver to get the source code\n",
    "\n",
    "all_soup = BeautifulSoup(page.content) # To Assign the page content to the variable soup\n",
    "movietitle = all_soup.find_all('td', class_=\"titleColumn\")\n",
    "movietitle\n",
    "ind_movies = []\n",
    "\n",
    "for ind_movie in movietitle:\n",
    "    ind_movie = ind_movie.get_text().replace('\\n', \"\")\n",
    "    ind_movie = ind_movie.strip(\" \")\n",
    "    ind_movies.append(ind_movie)\n",
    "ind_movies[:250]\n",
    "\n",
    "ind_scraped_ratings = ind_soup.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "ind_scraped_ratings\n",
    "\n",
    "ind_ratings = []\n",
    "for ind_rating in ind_scraped_ratings:\n",
    "    ind_rating = ind_rating.get_text().replace('\\n', '')\n",
    "    ind_ratings.append(ind_rating)\n",
    "ind_ratings[:250]\n",
    "\n",
    "import pandas as pd\n",
    "ind_data = pd.DataFrame()\n",
    "ind_data['Movie Names'] = ind_movies[:250]\n",
    "ind_data['Ratings'] = ind_ratings[:250]\n",
    "ind_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9cc0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2414f97",
   "metadata": {},
   "source": [
    "Q-4-Write s python program to display list of respected former presidents of India(i.e. Name , Term of office)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b982a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def html_content(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    names_of_the_president = soup.find_all(\"div\", class_ = \"presidentListing\")\n",
    "    Name = []\n",
    "    for i in names_of_the_president:\n",
    "        i = i.text\n",
    "        head,sep,tail = i.partition('(')\n",
    "        Name.append(head.replace('\\n',''))\n",
    "\n",
    "    term_of_office = soup.find_all(\"div\", class_ = \"presidentListing\")\n",
    "    Term = []\n",
    "    for i in term_of_office:\n",
    "        i = i.text\n",
    "        head,sep,tail = i.partition('Term of Office: ')\n",
    "        i = tail\n",
    "        head,sep,tail = i.partition('\\n')\n",
    "        Term.append(head)\n",
    "        \n",
    "    data = pd.DataFrame({\"Name of the Indian President\" : Name, \"Term of Office\" : Term})\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7009ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the Indian President</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name of the Indian President  \\\n",
       "0           Shri Ram Nath Kovind    \n",
       "1          Shri Pranab Mukherjee    \n",
       "2   Smt Pratibha Devisingh Patil    \n",
       "3         DR. A.P.J. Abdul Kalam    \n",
       "4           Shri K. R. Narayanan    \n",
       "5        Dr Shankar Dayal Sharma    \n",
       "6            Shri R Venkataraman    \n",
       "7               Giani Zail Singh    \n",
       "8      Shri Neelam Sanjiva Reddy    \n",
       "9       Dr. Fakhruddin Ali Ahmed    \n",
       "10  Shri Varahagiri Venkata Giri    \n",
       "11              Dr. Zakir Husain    \n",
       "12  Dr. Sarvepalli Radhakrishnan    \n",
       "13           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term of Office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10  3 May, 1969 to 20 July, 1969 and 24 August, 19...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content(\"https://presidentofindia.nic.in/former-presidents.htm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18d7c3b",
   "metadata": {},
   "source": [
    "Q-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4d7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def html_content(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    name_of_the_batsman = soup.find_all('td', class_ = 'table-body__cell name')\n",
    "    Top_player = soup.find('div', class_ = 'rankings-block__banner--name').text\n",
    "    Name = [Top_player]\n",
    "    for i in name_of_the_batsman:\n",
    "        Name.append(i.text.replace('\\n','')) \n",
    "    Name = Name[:10]\n",
    "\n",
    "    rating_of_the_batsman = soup.find_all('td', class_ = 'table-body__cell u-text-right rating')\n",
    "    Top_player_rating = soup.find('div', class_ = 'rankings-block__banner--rating').text\n",
    "    Rating = [Top_player_rating]\n",
    "    for i in rating_of_the_batsman:\n",
    "        i = i.text\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    team_name = soup.find_all('span', class_ = 'table-body__logo-text')\n",
    "    Top_player_team = soup.find('div', class_ = 'rankings-block__banner--nationality').text.replace('\\n','').split(' ')[0]\n",
    "    Team = [Top_player_team]\n",
    "    for i in team_name:\n",
    "        i = i.text.replace('\\n','')\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    data = pd.DataFrame({'Name of the Batsman':Name, 'Name of the Team':Team, 'Rating of the Player':Rating})\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb92d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the Batsman</th>\n",
       "      <th>Name of the Team</th>\n",
       "      <th>Rating of the Player</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name of the Batsman Name of the Team Rating of the Player\n",
       "0             Babar Azam              PAK                  890\n",
       "1  Rassie van der Dussen               SA                  789\n",
       "2        Quinton de Kock               SA                  784\n",
       "3            Imam-ul-Haq              PAK                  779\n",
       "4            Virat Kohli              IND                  744\n",
       "5           Rohit Sharma              IND                  740\n",
       "6         Jonny Bairstow              ENG                  732\n",
       "7           David Warner              AUS                  725\n",
       "8            Ross Taylor               NZ                  701\n",
       "9            Steve Smith              AUS                  697"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96247526",
   "metadata": {},
   "source": [
    "Q-6 Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf519df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def html_content(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    name_of_the_batswoman = soup.find_all('td', class_ = 'table-body__cell rankings-table__name name')\n",
    "    Top_player = soup.find('div', class_ = 'rankings-block__banner--name-large').text\n",
    "    Name = [Top_player]\n",
    "    for i in name_of_the_batswoman:\n",
    "        Name.append(i.text.replace('\\n','')) \n",
    "    Name = Name[:10]\n",
    "\n",
    "    rating_of_the_player = soup.find_all('td', class_ = 'table-body__cell rating')\n",
    "    Top_player_rating = soup.find('div', class_ = 'rankings-block__banner--rating').text\n",
    "    Rating = [Top_player_rating]\n",
    "    for i in rating_of_the_player:\n",
    "        i = i.text\n",
    "        Rating.append(i)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "    team_name = soup.find_all('span', class_ = 'table-body__logo-text')\n",
    "    Top_player_team = soup.find('div', class_ = 'rankings-block__banner--nationality').text.replace('\\n','')\n",
    "    Team = [Top_player_team]\n",
    "    for i in team_name:\n",
    "        i = i.text.replace('\\n','')\n",
    "        Team.append(i)\n",
    "    Team = Team[:10]\n",
    "\n",
    "    data = pd.DataFrame({'Name of the Batswoman':Name, 'Name of the Team':Team, 'Rating of the Player':Rating})\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7879014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the Batswoman</th>\n",
       "      <th>Name of the Team</th>\n",
       "      <th>Rating of the Player</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name of the Batswoman         Name of the Team Rating of the Player\n",
       "0          Alyssa Healy  AUS                                      785\n",
       "1           Beth Mooney                      AUS                  749\n",
       "2        Natalie Sciver                      ENG                  740\n",
       "3       Laura Wolvaardt                       SA                  732\n",
       "4           Meg Lanning                      AUS                  710\n",
       "5        Rachael Haynes                      AUS                  701\n",
       "6       Smriti Mandhana                      IND                  698\n",
       "7     Amy Satterthwaite                       NZ                  681\n",
       "8      Harmanpreet Kaur                      IND                  662\n",
       "9   Chamari Athapaththu                       SL                  655"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65a272",
   "metadata": {},
   "source": [
    "Q-7-Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31abbc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def html_content(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    title = soup.find_all('a', class_ ='LatestNews-headline')\n",
    "    Title = []\n",
    "    for i in title:\n",
    "        Title.append(i.text) \n",
    "\n",
    "    time = soup.find_all('time', class_ ='LatestNews-timestamp')\n",
    "    Time = []\n",
    "    for i in time:\n",
    "        Time.append(i.text) \n",
    "\n",
    "    link = soup.find_all('div', class_='LatestNews-headlineWrapper')\n",
    "    Link = []\n",
    "    for i in link:\n",
    "        head, sep, tail = str(i).partition('\" title=')\n",
    "        head, sep, tail = head.partition('a class=\"LatestNews-headline\" href=\"')\n",
    "        Link.append(tail)\n",
    "\n",
    "    data = pd.DataFrame({'Title of the News':Title,'Time of the News':Time,'Link of the News':Link})\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20af780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title of the News</th>\n",
       "      <th>Time of the News</th>\n",
       "      <th>Link of the News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Everything parents need to know about student ...</td>\n",
       "      <td>25 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/what-parent-pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Check in, smoke up and tune out: Cannabis-frie...</td>\n",
       "      <td>26 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/check-in-smoke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Convertibles drive into the sunset as automake...</td>\n",
       "      <td>26 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/convertible-sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Britain's sudden lurch to 'Reaganomics' gets a...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/24/liz-truss-brit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here's our plan for Monday after another painf...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/it-was-another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What to watch in the markets in the week ahead</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/stocks-could-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pro Picks: Watch all of Friday's big stock cal...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/pro-picks-watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13 careers where over 50% of workers are happy...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/careers-where-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New York AG wrongly said Yankees game on Apple...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/new-york-ag-wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tech stocks just had the worst two-week stretc...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/tech-stocks-wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Takeaways from Jim Cramer's interviews with th...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/jim-cramer-sat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Some homebuyers are facing mortgage 'payment s...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/some-homebuyer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ether is down almost 20% since the merge. Here...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/ether-is-down-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Elon Musk has over 20 direct reports at Tesla ...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/elon-musk-dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Trump SPAC shares are now around $16 after hit...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/trump-merger-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Here's why U.S. fiscal policy is undermining t...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/us-fiscal-poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Why gold and crypto haven't proven to be 'infl...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/why-gold-and-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Amid U.S. recession fears, these 4 steps can h...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/amid-us-recess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Biden promises to codify Roe if two more Democ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/biden-promises...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Government bond yields soar as markets weigh t...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/government-bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Inside the $250 million penthouse on 'Billiona...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/inside-the-250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Stocks making the biggest moves midday: FedEx,...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How the IPO market went from 'boom to bust' in...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/stock-market-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3 takeaways from our daily meeting: Bonds vs. ...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/3-takeaways-fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hedge funds ramp up bets as volatility brings ...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/hedge-funds-ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Celsius has a Hail Mary bankruptcy plan: Turn ...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/celsius-has-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lauren Taylor Wolfe says it's just too risky f...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/lauren-taylor-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Top stock performers this week make recession-...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/the-top-stock-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Legendary music producer Emilio Estefan urges ...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/emilio-estefan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Debt-loaded cruise lines' shares fall as Fed h...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/23/cruise-line-st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Title of the News Time of the News  \\\n",
       "0   Everything parents need to know about student ...       25 Min Ago   \n",
       "1   Check in, smoke up and tune out: Cannabis-frie...       26 Min Ago   \n",
       "2   Convertibles drive into the sunset as automake...       26 Min Ago   \n",
       "3   Britain's sudden lurch to 'Reaganomics' gets a...      4 Hours Ago   \n",
       "4   Here's our plan for Monday after another painf...     15 Hours Ago   \n",
       "5      What to watch in the markets in the week ahead     15 Hours Ago   \n",
       "6   Pro Picks: Watch all of Friday's big stock cal...     15 Hours Ago   \n",
       "7   13 careers where over 50% of workers are happy...     15 Hours Ago   \n",
       "8   New York AG wrongly said Yankees game on Apple...     15 Hours Ago   \n",
       "9   Tech stocks just had the worst two-week stretc...     16 Hours Ago   \n",
       "10  Takeaways from Jim Cramer's interviews with th...     16 Hours Ago   \n",
       "11  Some homebuyers are facing mortgage 'payment s...     17 Hours Ago   \n",
       "12  Ether is down almost 20% since the merge. Here...     17 Hours Ago   \n",
       "13  Elon Musk has over 20 direct reports at Tesla ...     17 Hours Ago   \n",
       "14  Trump SPAC shares are now around $16 after hit...     18 Hours Ago   \n",
       "15  Here's why U.S. fiscal policy is undermining t...     18 Hours Ago   \n",
       "16  Why gold and crypto haven't proven to be 'infl...     18 Hours Ago   \n",
       "17  Amid U.S. recession fears, these 4 steps can h...     18 Hours Ago   \n",
       "18  Biden promises to codify Roe if two more Democ...     18 Hours Ago   \n",
       "19  Government bond yields soar as markets weigh t...     19 Hours Ago   \n",
       "20  Inside the $250 million penthouse on 'Billiona...     19 Hours Ago   \n",
       "21  Stocks making the biggest moves midday: FedEx,...     19 Hours Ago   \n",
       "22  How the IPO market went from 'boom to bust' in...     19 Hours Ago   \n",
       "23  3 takeaways from our daily meeting: Bonds vs. ...     19 Hours Ago   \n",
       "24  Hedge funds ramp up bets as volatility brings ...     19 Hours Ago   \n",
       "25  Celsius has a Hail Mary bankruptcy plan: Turn ...     19 Hours Ago   \n",
       "26  Lauren Taylor Wolfe says it's just too risky f...     19 Hours Ago   \n",
       "27  Top stock performers this week make recession-...     19 Hours Ago   \n",
       "28  Legendary music producer Emilio Estefan urges ...     20 Hours Ago   \n",
       "29  Debt-loaded cruise lines' shares fall as Fed h...     20 Hours Ago   \n",
       "\n",
       "                                     Link of the News  \n",
       "0   https://www.cnbc.com/2022/09/24/what-parent-pl...  \n",
       "1   https://www.cnbc.com/2022/09/24/check-in-smoke...  \n",
       "2   https://www.cnbc.com/2022/09/24/convertible-sa...  \n",
       "3   https://www.cnbc.com/2022/09/24/liz-truss-brit...  \n",
       "4   https://www.cnbc.com/2022/09/23/it-was-another...  \n",
       "5   https://www.cnbc.com/2022/09/23/stocks-could-c...  \n",
       "6   https://www.cnbc.com/2022/09/23/pro-picks-watc...  \n",
       "7   https://www.cnbc.com/2022/09/23/careers-where-...  \n",
       "8   https://www.cnbc.com/2022/09/23/new-york-ag-wr...  \n",
       "9   https://www.cnbc.com/2022/09/23/tech-stocks-wo...  \n",
       "10  https://www.cnbc.com/2022/09/23/jim-cramer-sat...  \n",
       "11  https://www.cnbc.com/2022/09/23/some-homebuyer...  \n",
       "12  https://www.cnbc.com/2022/09/23/ether-is-down-...  \n",
       "13  https://www.cnbc.com/2022/09/23/elon-musk-dire...  \n",
       "14  https://www.cnbc.com/2022/09/23/trump-merger-p...  \n",
       "15  https://www.cnbc.com/2022/09/23/us-fiscal-poli...  \n",
       "16  https://www.cnbc.com/2022/09/23/why-gold-and-c...  \n",
       "17  https://www.cnbc.com/2022/09/23/amid-us-recess...  \n",
       "18  https://www.cnbc.com/2022/09/23/biden-promises...  \n",
       "19  https://www.cnbc.com/2022/09/23/government-bon...  \n",
       "20  https://www.cnbc.com/2022/09/23/inside-the-250...  \n",
       "21  https://www.cnbc.com/2022/09/23/stocks-making-...  \n",
       "22  https://www.cnbc.com/2022/09/23/stock-market-i...  \n",
       "23  https://www.cnbc.com/2022/09/23/3-takeaways-fr...  \n",
       "24  https://www.cnbc.com/2022/09/23/hedge-funds-ra...  \n",
       "25  https://www.cnbc.com/2022/09/23/celsius-has-a-...  \n",
       "26  https://www.cnbc.com/2022/09/23/lauren-taylor-...  \n",
       "27  https://www.cnbc.com/2022/09/23/the-top-stock-...  \n",
       "28  https://www.cnbc.com/2022/09/23/emilio-estefan...  \n",
       "29  https://www.cnbc.com/2022/09/23/cruise-line-st...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content('https://www.cnbc.com/world/?region=world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e1f0e",
   "metadata": {},
   "source": [
    "Q-8.Write a python program to scrape the details of most downloaded articles from AI in last 90 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "# Scrape below mentioned details :\n",
    "# i)   Paper Title\n",
    "# ii)  Authors\n",
    "# iii) Published Date\n",
    "# iv)  Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "480e733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles') # Send request to webserver to get the source code\n",
    "\n",
    "soup = BeautifulSoup(page.content) # To Assign the page content to the variable soup\n",
    "soup\n",
    "\n",
    "paper_title = []\n",
    "authors = []\n",
    "published_date = []\n",
    "paper_url = []\n",
    "\n",
    "# Assigning Paper title to a variable\n",
    "for title in soup.find_all('h2', class_='sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR'):\n",
    "    paper_title.append(title.text)\n",
    "paper_title\n",
    "\n",
    "# Assigning authors name to a variable\n",
    "for title in soup.find_all('span', class_='sc-1w3fpd7-0 pgLAT'):\n",
    "    authors.append(title.text)\n",
    "authors\n",
    "\n",
    "# Assigning published date to a variable\n",
    "for title in soup.find_all('span', class_='sc-1thf9ly-2 bKddwo'):\n",
    "    published_date.append(title.text)\n",
    "published_date\n",
    "\n",
    "# Assigning urls to a variable\n",
    "for title in soup.find_all('a', class_='sc-5smygv-0 nrDZj'):\n",
    "    paper_url.append(title.get('href'))\n",
    "paper_url\n",
    "\n",
    "\n",
    "# Assigning data to the Dataframe\n",
    "import pandas as pd\n",
    "data = pd.DataFrame()\n",
    "data['Paper Title'] = paper_title\n",
    "data['Authors'] = authors\n",
    "data['Published Date'] = published_date\n",
    "data['Paper URL'] = paper_url\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6800a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc317cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9aa35673",
   "metadata": {},
   "source": [
    "Q-9-Write a python program to scrape mentioned details from dineout.co.in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2381de88",
   "metadata": {},
   "source": [
    "import all required libraries:-\n",
    "    a)requests-send get request to web page to get source code\n",
    "    b)beautiful soup-It will be used to parse the source code and to extract the required data from parsed structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e2d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81f77593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56add1",
   "metadata": {},
   "source": [
    "Send get requests to the webpage server to get the source code of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d35352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://www.dineout.co.in/delhi-restaurants?search_str=buffet')\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3230b",
   "metadata": {},
   "source": [
    "Page Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954340b8",
   "metadata": {},
   "source": [
    "# Scrapping First Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a8cb2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a analytics-action=\"RestaurantCardClick\" analytics-label=\"27452_Local\" class=\"restnt-name ellipsis\" data-w-onclick=\"sendAnalyticsCommon|w1-restarant\" href=\"/delhi/local-connaught-place-central-delhi-27452\">Local</a>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_title=soup.find('a',class_=\"restnt-name ellipsis\")\n",
    "first_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f0cda10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Local'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80954a",
   "metadata": {},
   "source": [
    "# Scrapping First Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46f4476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scindia House,Connaught Place, Central Delhi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc=soup.find('div',class_=\"restnt-loc ellipsis\")\n",
    "loc.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d1e45",
   "metadata": {},
   "source": [
    "# Scrapping Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0d8b85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'₹ 2,000 for 2 (approx) '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price=soup.find('span',class_=\"double-line-ellipsis\")\n",
    "price.text.split(\"|\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bee3c3",
   "metadata": {},
   "source": [
    "# Scrapping Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "982e0771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' North Indian, Asian, Continental'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine=soup.find('span',class_=\"double-line-ellipsis\")\n",
    "cuisine.text.split(\"|\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39bd5a6",
   "metadata": {},
   "source": [
    "# Scrapping Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4313508f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/b/t/p27452-15020105505986dcb6d147f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/m/u/p31393-15972091555f337a43bb961.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/t/u/p237-16468990666229af7a72b08.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/u/y/p20941-15700828565d959028e9f28.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/y/j/p21171-166019927162f4a167b10af.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/e/u/p80493-16064603115fc0a397716de.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/9/h/n/p95-16444959626205045ab0b43.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/e/z/p53380-15544492915ca7038b700f1.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/9/u/b/p919-150182627559840ce33f574.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/d/l/p29673-1500453055596f18bfe2cab.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/e/u/p456-14473237645644687422a28.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/u/n/p2617-1617631577606b19598001e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/m/h/p35926-15233509655acc7db5718fb.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/k/v/p3094-1617661641606b8ec9027d2.JPG?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/j/a/p54792-1630486205612f3ebd9d20b.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/k/a/p33299-1651131064626a42b8c2849.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/g/p/p19259-15110746465a112b562861e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/x/k/p87447-161588804660507eaee6e94.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/n/c/p5364-1612339053601a576da7cd9.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/s/m/p46858-162151010960a647dd9b1ad.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images=[]\n",
    "for i in soup.find_all(\"img\",class_=\"no-img\"):\n",
    "    images.append(i.get('data-src'))\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e009b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30011fa8",
   "metadata": {},
   "source": [
    "Q-10  Write a python program to scrape the details of top publications from Google Scholar from \n",
    "      https://scholar.google.com/citations?view_op=top_venues&hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea93a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def html_content(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    rank = soup.find_all('td', class_ ='gsc_mvt_p')\n",
    "    Rank = []\n",
    "    for i in rank:\n",
    "        Rank.append(i.text) \n",
    "\n",
    "    publication = soup.find_all('td', class_ ='gsc_mvt_t')\n",
    "    Publication = []\n",
    "    for i in publication:\n",
    "        Publication.append(i.text) \n",
    "\n",
    "    h5_index = soup.find_all('a', class_ ='gs_ibl gsc_mp_anchor')\n",
    "    H5_index = []\n",
    "    for i in h5_index:\n",
    "        H5_index.append(i.text) \n",
    "\n",
    "    h5_median = soup.find_all('span', class_ ='gs_ibl gsc_mp_anchor')\n",
    "    H5_median = []\n",
    "    for i in h5_median:\n",
    "        H5_median.append(i.text)\n",
    "                                                        \n",
    "    data = pd.DataFrame({'Rank':Rank,'Publication':Publication,'h5_index':H5_index,'h5_median':H5_median})\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd0a57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5_index</th>\n",
       "      <th>h5_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5_index h5_median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content('https://scholar.google.com/citations?view_op=top_venues&hl=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef92e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
